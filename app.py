import streamlit as st
import pandas as pd
from PyPDF2 import PdfReader
from docx import Document
from io import BytesIO
import re
from collections import defaultdict

# -------------------------------------------------
# æå– PDF æ–‡æœ¬
# -------------------------------------------------
def extract_text_from_pdf(file):
    reader = PdfReader(file)
    text = ""
    for page in reader.pages:
        try:
            text += page.extract_text() + "\n"
        except:
            pass
    return text


# -------------------------------------------------
# æå– Word æ–‡æœ¬
# -------------------------------------------------
def extract_text_from_docx(file):
    doc = Document(file)
    text = ""
    for para in doc.paragraphs:
        text += para.text + "\n"
    return text


# -------------------------------------------------
# æ™ºèƒ½è§£æäº¤æ˜“æ–‡æœ¬ï¼ˆæ”¹è¿›ç‰ˆï¼‰
# -------------------------------------------------
def parse_transactions(text):
    grouped_data = defaultdict(list)
    lines = [l.strip() for l in text.split("\n") if l.strip()]
    current_name = None

    for line in lines:
        # è¯†åˆ«å®¢æˆ·åç§°ï¼ˆä¸€èˆ¬ä¸å«æ•°å­—ï¼‰
        if re.match(r"^[A-Za-z\s&.'()]+$", line, flags=re.I) or ("SDN BHD" in line.upper()):
            current_name = line.strip()
            continue

        # è¯†åˆ«äº¤æ˜“è¡Œï¼ˆåŒ…å«é‡‘é¢ï¼‰
        if current_name and re.search(r"[\d\.,-]+", line):
            grouped_data[current_name].append(line)

    return grouped_data


# -------------------------------------------------
# ç”Ÿæˆ Word æŠ¥å‘Šï¼ˆè‡ªåŠ¨æ¢è¡Œ + UTF-8 å…¼å®¹ï¼‰
# -------------------------------------------------
def generate_word_report(grouped_data):
    doc = Document()
    doc.add_heading("è½¬è´¦æ•´ç†æŠ¥å‘Š", level=1)

    for name, records in grouped_data.items():
        safe_name = str(name).encode("utf-8", "ignore").decode("utf-8", "ignore")
        doc.add_heading(safe_name, level=2)

        if not records:
            doc.add_paragraph("(æ— äº¤æ˜“è®°å½•)")
        else:
            for record in records:
                safe_record = str(record).encode("utf-8", "ignore").decode("utf-8", "ignore")
                doc.add_paragraph(safe_record)

    output = BytesIO()
    doc.save(output)
    output.seek(0)
    return output


# -------------------------------------------------
# Streamlit ä¸»é€»è¾‘
# -------------------------------------------------
st.set_page_config(page_title="è´¦å•è‡ªåŠ¨æ•´ç†åŠ©æ‰‹", page_icon="ğŸ’°")

st.title("ğŸ“„ è´¦å•è‡ªåŠ¨æ•´ç†åŠ©æ‰‹ï¼ˆæ”¯æŒå¤šé“¶è¡Œï¼‰")
st.markdown("ä¸Šä¼ ä½ çš„é“¶è¡Œè´¦å•ï¼ˆPDF æˆ– Wordï¼‰ï¼Œè‡ªåŠ¨è¯†åˆ«å®¢æˆ·ä¸äº¤æ˜“è®°å½•å¹¶å¯¼å‡º Word æŠ¥å‘Šã€‚")

uploaded_file = st.file_uploader("ä¸Šä¼ è´¦å•æ–‡ä»¶", type=["pdf", "docx"])

if uploaded_file:
    if uploaded_file.type == "application/pdf":
        text = extract_text_from_pdf(uploaded_file)
    else:
        text = extract_text_from_docx(uploaded_file)

    grouped_data = parse_transactions(text)

    if grouped_data:
        st.success(f"âœ… æ•´ç†å®Œæˆï¼Œå…±è¯†åˆ« {len(grouped_data)} ä½å®¢æˆ·ã€‚")

        if st.button("ğŸ“˜ ç”Ÿæˆ Word æŠ¥å‘Š"):
            try:
                word_file = generate_word_report(grouped_data)
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ Word æ–‡ä»¶",
                    data=word_file,
                    file_name="è½¬è´¦æ•´ç†æŠ¥å‘Š.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
            except Exception as e:
                st.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™ï¼š{e}")
    else:
        st.warning("âš ï¸ æ²¡æœ‰è¯†åˆ«åˆ°å®¢æˆ·æˆ–äº¤æ˜“è®°å½•ï¼Œè¯·ç¡®è®¤è´¦å•æ–‡å­—æ¸…æ™°ã€‚")
